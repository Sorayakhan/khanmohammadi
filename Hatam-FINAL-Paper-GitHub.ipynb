{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#فراخوانی داده\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,f1_score\n",
    "import seaborn\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,f1_score\n",
    "filepath = 'D:/Mr.hatam/Mr.hatam/Good Data.xlsx'\n",
    "df = pd.read_excel(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cancer end point'].replace({'incidence': 1, 'mortality':0}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set (rc = {'figure.figsize':(6, 5)})\n",
    "corr=df.corr()\n",
    "sns.heatmap(corr,annot=True,annot_kws={\"size\": 9})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.savefig('heatmap.png',  bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot=pd.get_dummies(df['cancer sitre'])\n",
    "df=df.drop('cancer sitre',axis=1)\n",
    "df=df.join(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cancer end point']=df.pop('Cancer end point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#درنظرگرفتن 8 ستون اول بعنوان ورودی \n",
    "X=df.iloc[:,0:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#درنظرگرفتن ستون آخر بعنوان خروجی\n",
    "y=df.iloc[:,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=preprocessing.MinMaxScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'n_estimators':[100,500,1000,1500]}\n",
    "grid=GridSearchCV(estimator=AdaBoostClassifier(),param_grid=param_grid,cv=4)  \n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "skf=StratifiedKFold(n_splits=5)\n",
    "boost=AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "score1=cross_val_score(boost,X_train,y_train,cv=skf,scoring='accuracy')\n",
    "score2=cross_val_score(boost,X_train,y_train,cv=skf,scoring='precision')\n",
    "score3=cross_val_score(boost,X_train,y_train,cv=skf,scoring='recall')\n",
    "score4=cross_val_score(boost,X_train,y_train,cv=skf,scoring='f1')\n",
    "print(\"Cross Validation Scores are {}\".format(score1))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score1.mean(), score1.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score2))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score2.mean(), score2.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score3))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score3.mean(), score3.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score4))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score4.mean(), score4.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost=AdaBoostClassifier(n_estimators=100)\n",
    "boost.fit(X_train,y_train)\n",
    "\n",
    "y_predicted_prob=boost.predict_proba(X_test)\n",
    "\n",
    "y_predicted=boost.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,boost.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'n_estimators':[100,500,1000,1500]}\n",
    "grid=GridSearchCV(estimator=BaggingClassifier(),param_grid=param_grid,cv=4)  \n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf=StratifiedKFold(n_splits=5)\n",
    "bag=BaggingClassifier(n_estimators=100,oob_score=True)\n",
    "score1=cross_val_score(bag,X_train,y_train,cv=skf,scoring='accuracy')\n",
    "score2=cross_val_score(bag,X_train,y_train,cv=skf,scoring='precision')\n",
    "score3=cross_val_score(bag,X_train,y_train,cv=skf,scoring='recall')\n",
    "score4=cross_val_score(bag,X_train,y_train,cv=skf,scoring='f1')\n",
    "print(\"Cross Validation Scores are {}\".format(score1))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score1.mean(), score1.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score2))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score2.mean(), score2.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score3))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score3.mean(), score3.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score4))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score4.mean(), score4.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag=BaggingClassifier(n_estimators=100,oob_score=True)\n",
    "bag.fit(X_train,y_train)\n",
    "y_predicted=bag.predict(X_test)\n",
    "print(confusion_matrix(y_test,bag.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'n_estimators':[100,500,1000,1500]}\n",
    "grid=GridSearchCV(estimator=RandomForestClassifier(),param_grid=param_grid,cv=4)  \n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "skf=StratifiedKFold(n_splits=5)\n",
    "rf=RandomForestClassifier(n_estimators=100,oob_score=True,max_features='auto')\n",
    "score1=cross_val_score(rf,X_train,y_train,cv=skf,scoring='accuracy')\n",
    "score2=cross_val_score(rf,X_train,y_train,cv=skf,scoring='precision')\n",
    "score3=cross_val_score(rf,X_train,y_train,cv=skf,scoring='recall')\n",
    "score4=cross_val_score(rf,X_train,y_train,cv=skf,scoring='f1')\n",
    "print(\"Cross Validation Scores are {}\".format(score1))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score1.mean(), score1.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score2))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score2.mean(), score2.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score3))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score3.mean(), score3.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score4))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score4.mean(), score4.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100,oob_score=True,max_features='auto')\n",
    "rf.fit(X_train,y_train)\n",
    "y_predicted=rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search\n",
    "from sklearn import tree\n",
    "tree_param={'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10]}\n",
    "grid=GridSearchCV(tree.DecisionTreeClassifier(),param_grid=tree_param,scoring='f1',cv=4)\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cross validation\n",
    "skf=StratifiedKFold(n_splits=5)\n",
    "dectree=tree.DecisionTreeClassifier(max_depth=10)\n",
    "score1=cross_val_score(dectree,X_train,y_train,cv=skf,scoring='accuracy')\n",
    "score2=cross_val_score(dectree,X_train,y_train,cv=skf,scoring='precision')\n",
    "score3=cross_val_score(dectree,X_train,y_train,cv=skf,scoring='recall')\n",
    "score4=cross_val_score(dectree,X_train,y_train,cv=skf,scoring='f1')\n",
    "print(\"Cross Validation Scores are {}\".format(score1))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score1.mean(), score1.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score2))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score2.mean(), score2.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score3))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score3.mean(), score3.std()))\n",
    "print(\"Cross Validation Scores are {}\".format(score4))\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (score4.mean(), score4.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree=tree.DecisionTreeClassifier(max_depth=10)\n",
    "dectree.fit(X_train,y_train)\n",
    "y_predicted=dectree.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,dectree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [AdaBoostClassifier(n_estimators=100), \n",
    "               BaggingClassifier(n_estimators=100), \n",
    "               RandomForestClassifier(n_estimators=100), \n",
    "               tree.DecisionTreeClassifier(max_depth=10)]\n",
    "\n",
    "# Define a result table as a DataFrame\n",
    "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train the models and record the results\n",
    "for cls in classifiers:\n",
    "    model = cls.fit(X_train, y_train)\n",
    "    \n",
    "    yproba = model.predict(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "    auc = roc_auc_score(y_test, yproba)\n",
    "    \n",
    "    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n",
    "                                        'fpr':fpr, \n",
    "                                        'tpr':tpr, \n",
    "                                        'auc':auc}, ignore_index=True)\n",
    "\n",
    "# Set name of the classifiers as index labels\n",
    "result_table.set_index('classifiers', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "\n",
    "for i in result_table.index:\n",
    "    plt.plot(result_table.loc[i]['fpr'], \n",
    "             result_table.loc[i]['tpr'], \n",
    "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
    "    \n",
    "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"Flase Positive Rate\", fontsize=13)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=13)\n",
    "\n",
    "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=13)\n",
    "plt.legend(prop={'size':10}, loc='lower right')\n",
    "\n",
    "plt.grid(linestyle='-', linewidth=0.25)\n",
    "plt.savefig('plot1.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "feature_scores = pd.DataFrame(feature_scores, columns=[\"FI\"])\n",
    "\n",
    "feature_scores=feature_scores.iloc[0:6,:]\n",
    "feature_scores=feature_scores.round(3)\n",
    "\n",
    "# Display the plot\n",
    "ax=feature_scores.plot(kind='bar',color='blue')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005), weight='bold')\n",
    "\n",
    "plt.title('Feature Importance', fontweight='bold', fontsize=13)\n",
    "plt.legend(prop={'size':10}, loc='lower right')\n",
    "\n",
    "plt.grid(linestyle='-', linewidth=0.25)    \n",
    "plt.savefig('plot2.png', dpi=300, bbox_inches='tight')\n",
    "plt.show    \n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "feature_scores = pd.DataFrame(feature_scores, columns=[\"FI\"])\n",
    "\n",
    "feature_scores=feature_scores.iloc[0:6,:]\n",
    "feature_scores=feature_scores.round(3)\n",
    "\n",
    "# Display the plot\n",
    "ax=feature_scores.plot.bar(rot=70, color='blue')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005), weight='bold')\n",
    "\n",
    "plt.title('Feature Importance', fontweight='bold', fontsize=13)\n",
    "plt.legend(prop={'size':10}, loc='lower right')\n",
    "\n",
    "plt.grid(linestyle='-', linewidth=0.25)    \n",
    "plt.savefig('plot3.png', dpi=300, bbox_inches='tight')\n",
    "plt.show    \n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100,oob_score=True,max_features='auto')\n",
    "rf.fit(X_train,y_train)\n",
    "y_predicted=rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,boost.predict(X_test)))\n",
    "print(y_predicted_prob)\n",
    "print(y_predicted)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = ['Bagging Classifier', metrics.accuracy_score(y_test, bag.predict(X_test)),\n",
    "     metrics.precision_score(y_test, bag.predict(X_test)),\n",
    " metrics.recall_score(y_test, bag.predict(X_test)),\n",
    "    metrics.f1_score(y_test, bag.predict(X_test))\n",
    "          ]\n",
    "\n",
    "scores1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = ['Boosting Classifier', metrics.accuracy_score(y_test, boost.predict(X_test)),\n",
    "     metrics.precision_score(y_test, boost.predict(X_test)),\n",
    " metrics.recall_score(y_test, boost.predict(X_test)),\n",
    "    metrics.f1_score(y_test, boost.predict(X_test))\n",
    "          ]\n",
    "print(confusion_matrix(y_test,boost.predict(X_test)))\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores3 = ['Random Forest', metrics.accuracy_score(y_test, rf.predict(X_test)),\n",
    "     metrics.precision_score(y_test, rf.predict(X_test)),\n",
    " metrics.recall_score(y_test, rf.predict(X_test)),\n",
    "    metrics.f1_score(y_test, rf.predict(X_test))\n",
    "          ]\n",
    "\n",
    "scores3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores4 = ['Decision Tree', metrics.accuracy_score(y_test, dectree.predict(X_test)),\n",
    "     metrics.precision_score(y_test, dectree.predict(X_test)),\n",
    " metrics.recall_score(y_test, dectree.predict(X_test)),\n",
    "    metrics.f1_score(y_test, dectree.predict(X_test))\n",
    "          ]\n",
    "\n",
    "print(scores4)\n",
    "print(confusion_matrix(y_test,dectree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[scores1]+[scores2]+[scores3]+[scores4]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiple columns bar chart\n",
    "\n",
    "df = pd.DataFrame(scores, columns=[\"Model Name\",\"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df=df.round(2)\n",
    "ax=df.plot(x=\"Model Name\", y=[\"Accuracy\", \"Precision\", \"Recall\", \"F1\"], kind=\"bar\",figsize=(10,6),rot=70 ,width= 0.7)\n",
    "# Display the plot\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005), weight='bold')\n",
    "ax.set_title('Performance comparison of classifiers on different evaluation metrics', fontweight =\"bold\") \n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(True, color='#EEEEEE')\n",
    "ax.xaxis.grid(False)\n",
    "plt.savefig('plot4.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
